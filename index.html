<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      ParallelBench: Understanding the Trade-offs of Parallel Decoding in
      Diffusion LLMs
    </title>
    <meta
      name="description"
      content="ParallelBench analyzes diffusion LLMs under parallel decoding, revealing the speed-quality trade-offs and benchmark tasks that surface token dependency failures."
    />
    <link rel="icon" href="favicon.ico" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap"
      rel="stylesheet"
    />
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            fontFamily: {
              sans: ['Inter', 'ui-sans-serif', 'system-ui'],
            },
            colors: {
              primary: '#1f6feb',
              slateInk: '#0b192f',
            },
            boxShadow: {
              card: '0 24px 48px -32px rgba(15, 23, 42, 0.35)',
            },
          },
        },
      };
    </script>
    <style>
      body {
        font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont,
          'Segoe UI', sans-serif;
      }
    </style>
  </head>
  <body class="bg-white text-slate-900 antialiased">
    <header
      class="sticky top-0 z-40 border-b border-slate-200 bg-white/90 backdrop-blur"
    >
      <div
        class="mx-auto flex max-w-6xl items-center justify-between px-6 py-3 lg:px-12"
      >
        <a
          href="#top"
          class="flex items-center gap-3 text-base font-semibold text-slate-800"
        >
          <img
            src="assets/images/logo.png"
            alt="ParallelBench logo"
            class="h-8 bg-white object-cover"
          />
          <span>ParallelBench</span>
        </a>
        <button
          type="button"
          id="menu-toggle"
          class="rounded-md border border-slate-200 px-3 py-2 text-sm font-medium text-slate-600 transition hover:border-primary/40 hover:text-primary lg:hidden"
        >
          Menu
        </button>
        <nav
          id="main-nav"
          class="hidden items-center gap-6 text-sm font-medium text-slate-600 lg:flex"
        >
          <a href="#overview" class="transition hover:text-primary">Overview</a>
          <a href="#benchmark" class="transition hover:text-primary"
            >Benchmark</a
          >
          <a href="#evaluation" class="transition hover:text-primary"
            >Evaluation</a
          >
          <a href="#findings" class="transition hover:text-primary">Findings</a>
          <a href="#citation" class="transition hover:text-primary">Citation</a>
        </nav>
      </div>
      <div
        id="mobile-nav"
        class="hidden border-t border-slate-200 bg-white px-6 py-4 text-sm font-medium text-slate-600 lg:hidden"
      >
        <div class="flex flex-col gap-3">
          <a href="#overview" class="transition hover:text-primary">Overview</a>
          <a href="#benchmark" class="transition hover:text-primary"
            >Benchmark</a
          >
          <a href="#evaluation" class="transition hover:text-primary"
            >Evaluation</a
          >
          <a href="#findings" class="transition hover:text-primary">Findings</a>
          <a href="#citation" class="transition hover:text-primary">Citation</a>
        </div>
      </div>
    </header>

    <main id="top">
      <section
        class="relative overflow-hidden bg-gradient-to-br from-slate-50 via-white to-white"
      >
        <div
          class="absolute -top-10 right-12 h-64 w-64 rounded-full bg-primary/10 blur-3xl"
        ></div>
        <div
          class="absolute bottom-24 left-12 h-80 w-80 rounded-full bg-slate-200/50 blur-3xl"
        ></div>
        <div
          class="relative mx-auto max-w-5xl px-6 pb-24 pt-16 text-center lg:px-12 lg:pb-28 lg:pt-20"
        >
          <div class="mx-auto flex w-full max-w-md flex-col items-center gap-4">
            <img
              src="assets/images/logo.png"
              alt="ParallelBench logo"
              class="h-28 object-cover"
            />
          </div>
          <h1
            class="mt-8 text-4xl font-bold leading-tight text-slateInk sm:text-5xl"
          >
            ParallelBench: Understanding the Trade-offs of Parallel Decoding in
            Diffusion LLMs
          </h1>
          <p class="mx-auto mt-6 max-w-3xl text-lg text-slate-600">
            Diffusion LLMs (dLLMs) promise massive speedups via parallel
            decoding, but their conditional-independence assumption breaks when
            tokens must coordinate. <b>ParallelBench</b> is the first benchmark
            designed explicitly for this failure mode. It pairs tractable theory
            with realistic tasks that humans and Autoregressive (AR) LLMs solve
            easily‚Äîbut where dLLMs collapse as parallelism grows‚Äîmaking the
            speed-quality trade-off measurable and comparable across models and
            decoding strategies.
          </p>
          <div class="mt-8 space-y-4 text-sm text-slate-600">
            <p class="mx-auto text-center max-w-2xl">
              Wonjun Kang*<sup>1,5</sup>, Kevin Galim*<sup>1</sup>, Seunghyuk
              Oh*<sup>1</sup>, Minjae Lee<sup>1</sup>, Yuchen
              Zeng<sup>2,3</sup>, Shuibai Zhang<sup>2</sup>, Coleman Richard
              Charles Hooper<sup>4</sup>, Yuezhou Hu<sup>4</sup>, Hyung Il
              Koo<sup>1</sup>, Nam Ik Cho<sup>5</sup>, Kangwook Lee<sup
                >2,6</sup
              >
            </p>
            <div
              class="flex flex-wrap items-center justify-center gap-4 text-xs text-slate-500"
            >
              <span
                ><strong><sup>1</sup> FuriosaAI</strong></span
              >
              <span
                ><strong><sup>2</sup> UW-Madison</strong></span
              >
              <span
                ><strong><sup>3</sup> Microsoft Research</strong></span
              >
              <span
                ><strong><sup>4</sup> UC Berkeley</strong></span
              >
              <span
                ><strong><sup>5</sup> Seoul National University</strong></span
              >
              <span
                ><strong><sup>6</sup> KRAFTON AI</strong></span
              >
            </div>
            <div class="text-xs text-slate-500">
              <p>*Equal Contribution</p>
            </div>
          </div>
          <div class="mt-10 flex flex-wrap items-center justify-center gap-4">
            <a
              href="https://github.com/furiosa-ai/ParallelBench"
              class="inline-flex items-center gap-2 rounded-full border border-slate-200 bg-white px-6 py-3 text-sm font-semibold text-slate-700 shadow-card transition hover:border-primary/40 hover:text-primary"
              target="_blank"
              rel="noopener noreferrer"
            >
              <span>GitHub Repository</span>
              <svg
                class="h-4 w-4"
                fill="none"
                stroke="currentColor"
                viewBox="0 0 24 24"
                xmlns="http://www.w3.org/2000/svg"
              >
                <path
                  stroke-linecap="round"
                  stroke-linejoin="round"
                  stroke-width="2"
                  d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"
                ></path>
              </svg>
            </a>
            <a
              href="#abstract"
              class="inline-flex items-center gap-2 rounded-full border border-primary/40 bg-primary/10 px-6 py-3 text-sm font-semibold text-primary transition hover:bg-primary/20"
            >
              <span>üìÑ</span>
              <span>Read the full Abstract</span>
            </a>
          </div>
        </div>
      </section>

      <section id="overview" class="bg-white py-20">
        <div class="mx-auto max-w-5xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Why ParallelBench?
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            Parallel decoding is fast, but not free. When outputs require
            token-to-token coordination, factorized predictions ignore
            dependencies, resulting in a drop in quality. Existing
            <i>math/coding</i> benchmarks rarely expose this.
            <b>ParallelBench</b> closes the gap with information-theoretic
            analysis and tasks explicitly designed to stress dependency
            handling.
          </p>
          <div class="mt-10 grid gap-6 sm:grid-cols-2 lg:grid-cols-3">
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Information-Theoretic Analysis
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                <u
                  >Proves that parallel decoding has fundamental error bounds
                  when tokens depend on each other</u
                >, showing even perfect models struggle as we increase
                parallelism on tasks requiring strong token coordination.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Quantitative Case Studies
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Analytically tractable synthetic list operations (<i
                  >Copy, Replace, Shuffle</i
                >) with closed-form accuracy formulas demonstrate fundamental
                limitations:
                <u
                  >specific tasks show inevitable quality degradation under
                  parallel decoding</u
                >.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Realistic Benchmark Tasks
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Seventeen tasks across
                <i>Waiting Line, Text Writing, and Puzzles</i>‚Äî<b
                  >all trivial for humans and autoregressive LLMs</b
                >‚Äîreveal severe quality degradation in dLLMs under parallel
                decoding in real-world scenarios.
              </p>
            </div>
          </div>
        </div>
      </section>

      <section
        id="benchmark"
        class="border-t border-slate-200 bg-slate-50 py-20"
      >
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Benchmark Highlights
          </h2>
          <div class="mt-10 grid gap-8 lg:grid-cols-[1.4fr,1fr]">
            <div class="space-y-6 text-base text-slate-600">
              <p>
                <b>ParallelBench</b> couples synthetic and realistic workloads
                to isolate where parallel decoding fails. Each family ships gold
                solutions, baselines, and instrumentation to measure latency,
                accuracy, and dependency violations under different unmasking
                policies.
              </p>
              <ul class="space-y-3 text-sm">
                <li>
                  ‚Ä¢ 17 tasks, 3 families: <i>Waiting Line</i> (10),
                  <i>Text Writing</i> (5), <i>Puzzles</i> (2).
                </li>
                <li>
                  ‚Ä¢ Knobbed difficulty to test parallelizability and adaptive
                  controllers.
                </li>
                <li>‚Ä¢ Reference implementations for dLLMs and AR baselines.</li>
                <li>
                  ‚Ä¢ Evaluation harness for both quality and realized speedup.
                </li>
              </ul>
            </div>
            <div
              class="rounded-3xl border border-primary/30 bg-primary/5 p-8 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-primary">What You Get</h3>
              <ul class="mt-4 space-y-3 text-sm text-slate-600">
                <li>
                  <strong>Datasets:</strong> JSON/CSV payloads with gold outputs
                  and scoring scripts.
                </li>
                <li>
                  <strong>Tracing Tools:</strong> Hooks to log per-step token
                  dependencies and failure reasons.
                </li>
                <li>
                  <strong>Reports:</strong> Ready-made notebooks summarizing
                  baseline parallelism‚Äìaccuracy curves.
                </li>
              </ul>
            </div>
          </div>
        </div>
      </section>
      <section id="details" class="bg-white pt-20 pb-10">
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Benchmark Details
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            <b>ParallelBench</b> consists of seventeen tasks across three
            categories. Together they reveal how parallel decoding struggles
            when tokens need to coordinate with each other, ranging from tasks
            where each token is independent to those requiring strong
            interdependencies.
          </p>
          <div class="mt-12 grid gap-8 lg:grid-cols-3">
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-slate-50 p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Waiting Line (10 tasks)
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Realistic customer service queue management tasks extending
                synthetic list operations:
                <i>Copy, Sort, Reverse, Shuffle, Index</i> (<i
                  >Insert, Replace, Remove</i
                >) and <i>Random</i> (same as <i>Index</i>) to expose where
                parallel decoding fails to maintain token dependencies.
              </p>
              <ul class="mt-6 space-y-2 text-sm text-slate-500"></ul>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-slate-50 p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Text Writing (5 tasks)
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Summarization, paraphrasing, and Words-to-Sentence generation
                tasks at varying difficulty levels that expose quality
                degradation through grammar scores and token-level dependencies.
              </p>
              <ul class="mt-6 space-y-2 text-sm text-slate-500"></ul>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-slate-50 p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Puzzles (2 tasks)
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                <i>Sudoku (4x4)</i> and <i>Latin Square (4x4)</i> tasks that
                compare structurally similar puzzles with different solution
                spaces to demonstrate how token dependencies affect parallel
                decoding performance.
              </p>
              <ul class="mt-6 space-y-2 text-sm text-slate-500"></ul>
            </div>
          </div>
        </div>
      </section>

      <section id="examples" class="bg-white pt-5 pb-20">
        <div class="mx-auto max-w-5xl px-6 lg:px-0">
          <div
            class="rounded-3xl border border-slate-200 bg-slate-50 p-6 text-sm text-slate-600 shadow-sm"
          >
            <h3 class="text-lg font-semibold text-slateInk">
              Sample Prompt: Waiting Line (Shuffle)
            </h3>
            <pre
              class="mt-4 overflow-x-auto rounded-2xl bg-slate-900/95 p-4 text-sm text-slate-100"
            >
You are managing a waiting line at a customer service desk.
The waiting line should be randomly shuffled to ensure fair service distribution:

["Thomas Holmes", "Keith Ramos", "Victoria Collins", "Roger Hughes", "Austin Dunn"].

Please randomly shuffle the list and provide only the final list.
Ensure the sequence is different from the original.</pre
            >
            <h3 class="mt-6 text-lg font-semibold text-slateInk">
              Sample Prompt: Text Writing (Words-to-Sentence)
            </h3>
            <pre
              class="mt-4 overflow-x-auto rounded-2xl bg-slate-900/95 p-4 text-sm text-slate-100"
            >
Construct a single, coherent sentence using the words algorithm, river, symphony, and moss.</pre
            >
            <h3 class="mt-6 text-lg font-semibold text-slateInk">
              Sample Prompt: Puzzles (Latin Square)
            </h3>
            <pre
              class="mt-4 overflow-x-auto rounded-2xl bg-slate-900/95 p-4 text-sm text-slate-100"
            >
Generate a Latin square of size 3 with the symbols [A, W, M]. Only output the final result as CSV.</pre
            >
          </div>
        </div>
      </section>

      <!-- <section
        id="evaluation"
        class="border-t border-slate-200 bg-slate-50 py-20"
      >
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Evaluation Framework
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            We use simple, task-specific evaluation metrics tailored to each
            category. For Waiting Line and Puzzles, we measure exact match
            accuracy. For Text Writing, we use grammar scoring combined with
            task-appropriate metrics.
          </p>
          <div class="mt-12 grid gap-8 lg:grid-cols-3">
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Waiting Line & Puzzles
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                <strong>Accuracy:</strong> Binary score indicating whether the
                generated output exactly matches one of the valid solutions. For
                structured tasks like queue management and logic puzzles, exact
                correctness is essential.
              </p>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">Text Writing</h3>
              <p class="mt-3 text-sm text-slate-600">
                <strong>Grammar Score:</strong> Evaluated using
                LanguageTool‚Äîoutputs receive 1 if grammatically correct, 0
                otherwise. Additional task-specific metrics include ROUGE-L for
                summarization, BERTScore and (1 - BLEU) for paraphrasing, and
                word inclusion accuracy for Words-to-Sentence tasks.
              </p>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Decoding Setup
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                All models use greedy decoding, except for infilling tasks which
                use temperature sampling (œÑ = 1.0). Maximum generation length is
                set to 32 tokens for Waiting Line and 64 tokens for both Puzzle
                and Text Writing tasks.
              </p>
            </div>
          </div>
        </div>
      </section> -->

      <section id="leaderboard" class="bg-white py-20">
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Baseline Snapshot
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            Autoregressive LLMs maintain high quality, while diffusion LLMs with
            parallel decoding (k=2) struggle with tasks requiring strong token
            dependencies. Results show average scores across Waiting Line tasks
            with n=3-6.
          </p>
          <div
            class="mt-10 overflow-x-auto rounded-3xl border border-slate-200 bg-white shadow-card"
          >
            <table class="min-w-full divide-y divide-slate-200 text-sm">
              <thead
                class="bg-slate-50 text-xs font-semibold uppercase tracking-wide text-slate-600"
              >
                <tr>
                  <th class="px-4 py-3 text-left">Model</th>
                  <th class="px-4 py-3 text-left">Type</th>
                  <th class="px-4 py-3 text-center">Copy</th>
                  <th class="px-4 py-3 text-center">Reverse</th>
                  <th class="px-4 py-3 text-center">Shuffle</th>
                  <th class="px-4 py-3 text-center">Replace Idx</th>
                  <th class="px-4 py-3 text-center">Replace Rand</th>
                </tr>
              </thead>
              <tbody class="divide-y divide-slate-100 text-slate-700">
                <tr class="bg-blue-50/40">
                  <td class="px-4 py-3 font-semibold">Llama 3.1 8B</td>
                  <td class="px-4 py-3">Autoregressive</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">96</td>
                  <td class="px-4 py-3 text-center">23</td>
                  <td class="px-4 py-3 text-center">88</td>
                </tr>
                <tr class="bg-blue-50/40">
                  <td class="px-4 py-3 font-semibold">Qwen3 4B</td>
                  <td class="px-4 py-3">Autoregressive</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">75</td>
                  <td class="px-4 py-3 text-center">97</td>
                  <td class="px-4 py-3 text-center">67</td>
                  <td class="px-4 py-3 text-center">92</td>
                </tr>
                <tr class="bg-blue-50/40">
                  <td class="px-4 py-3 font-semibold">Claude Haiku 3.5</td>
                  <td class="px-4 py-3">Closed (AR)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">32</td>
                  <td class="px-4 py-3 text-center">100</td>
                </tr>
                <tr class="bg-amber-50/60">
                  <td class="px-4 py-3 font-semibold">LLaDA 1.5</td>
                  <td class="px-4 py-3">Diffusion (k=2)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">99</td>
                  <td class="px-4 py-3 text-center">18</td>
                  <td class="px-4 py-3 text-center">15</td>
                  <td class="px-4 py-3 text-center">70</td>
                </tr>
                <tr class="bg-amber-50/60">
                  <td class="px-4 py-3 font-semibold">Dream 7B</td>
                  <td class="px-4 py-3">Diffusion (k=2)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">91</td>
                  <td class="px-4 py-3 text-center">87</td>
                  <td class="px-4 py-3 text-center">27</td>
                  <td class="px-4 py-3 text-center">99</td>
                </tr>
                <tr class="bg-amber-50/60">
                  <td class="px-4 py-3 font-semibold">Mercury</td>
                  <td class="px-4 py-3">Closed (Diffusion)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">92</td>
                  <td class="px-4 py-3 text-center">28</td>
                  <td class="px-4 py-3 text-center">98</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </section>

      <section
        id="findings"
        class="border-t border-slate-200 bg-slate-50 py-20"
      >
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Key Findings
          </h2>
          <div class="mt-12 grid gap-8 lg:grid-cols-2">
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                ‚ö†Ô∏è Quality Collapse Under Independence
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                When token dependencies exceed the parallel decoding horizon,
                accuracy can drop by 20‚Äì40 points‚Äîeven on analytically simple
                tasks‚Äîdue to factorization error.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                ‚öñÔ∏è Speed vs. Quality Trade-off
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Static top-k parallelism rarely nets wins: throughput plateaus
                (&lt;1.5√ó) while accuracy degrades (&gt;15 pts). Adaptive
                thresholds help but still leave large headroom.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                üß† Adaptivity Is Lacking
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Current heuristics do not dial back parallelism on hard inputs.
                Dependency-aware controllers are needed to modulate
                tokens-per-step per sample.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                üõ†Ô∏è Benchmark as a Guide
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                ParallelBench localizes failure modes, enabling principled
                research on hybrid/ semi-AR decoding and improved diffusion
                objectives.
              </p>
            </div>
          </div>
        </div>
      </section>

      <section id="abstract" class="bg-white py-20">
        <div class="mx-auto max-w-4xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Abstract
          </h2>
          <div
            class="mt-8 space-y-6 text-justify text-base leading-7 text-slate-600"
          >
            <p>
              While most autoregressive LLMs are constrained to one-by-one
              decoding, diffusion LLMs (dLLMs) have attracted growing interest
              for their potential to dramatically accelerate inference through
              parallel decoding. Despite this promise, the conditional
              independence assumption in dLLMs causes parallel decoding to
              ignore token dependencies, inevitably degrading generation quality
              when these dependencies are strong. However, existing works
              largely overlook these inherent challenges, and evaluations on
              standard benchmarks (e.g., math and coding) are not sufficient to
              capture the quality degradation caused by parallel decoding. To
              address this gap, we first provide an information-theoretic
              analysis of parallel decoding. We then conduct case studies on
              analytically tractable synthetic list operations from both data
              distribution and decoding strategy perspectives, offering
              quantitative insights that highlight the fundamental limitations
              of parallel decoding. Building on these insights, we propose
              ParallelBench, the first benchmark specifically designed for
              dLLMs, featuring realistic tasks that are trivial for humans and
              autoregressive LLMs yet exceptionally challenging for dLLMs under
              parallel decoding. Using ParallelBench, we systematically analyze
              both dLLMs and autoregressive LLMs, revealing that: (i) dLLMs
              under parallel decoding can suffer dramatic quality degradation in
              real-world scenarios, and (ii) current parallel decoding
              strategies struggle to adapt their degree of parallelism based on
              task difficulty, thus failing to achieve meaningful speedup
              without compromising quality. Our findings underscore the pressing
              need for innovative decoding methods that can overcome the current
              speed-quality trade-off. We are releasing our benchmark to help
              accelerate the development of truly efficient dLLMs.
            </p>
          </div>
          <div class="mx-auto mt-12 max-w-6xl px-6 lg:px-0">
            <div
              class="overflow-hidden rounded-3xl border border-slate-200 bg-white shadow-card p-6 lg:p-8 cursor-pointer transition hover:shadow-xl"
              onclick="openImageModal()"
            >
              <img
                src="assets/images/teaser_figure.png"
                alt="ParallelBench: Overview of limitations, analysis, and benchmark"
                class="w-full"
              />
            </div>
            <p class="mt-4 text-center text-sm text-slate-500">
              ParallelBench: (left) Parallel decoding mixes individually likely
              tokens into invalid pairs when dependencies are ignored (e.g.,
              ‚ÄúNew‚Äù + ‚ÄúCity‚Äù). (middle) Closed-form analyses on list operations
              quantify accuracy decay as parallelism increases. (right) A
              realistic benchmark exposes speed‚Äìquality trade-offs across dLLMs
              and decoding strategies.
            </p>
          </div>
        </div>
      </section>
    </main>

    <footer id="citation" class="border-t border-slate-200 bg-slate-50 py-12">
      <div
        class="mx-auto flex max-w-5xl flex-col items-center gap-4 px-6 text-center text-sm text-slate-500"
      >
        <h3 class="text-base font-semibold text-slateInk">Citation</h3>
        <pre
          class="w-full overflow-x-auto rounded-3xl border border-slate-200 bg-slate-900/95 p-6 text-left text-sm text-slate-100"
        >
@misc{parallelbench2025,
  title={ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs},
  author={Wonjun Kang and Kevin Galim and Seunghyuk Oh and Minjae Lee and Yuchen Zeng and
          Shuibai Zhang and Coleman Richard Charles Hooper and Yuezhou Hu and
          Hyung Il Koo and Nam Ik Cho and Kangwook Lee},
  year={2025},
  note={Under review as a conference paper at ICLR 2026},
  howpublished={\url{https://github.com/furiosa-ai/ParallelBench}}
}</pre
        >
        <p>
          This webpage is licensed under a
          <a
            href="http://creativecommons.org/licenses/by-sa/4.0/"
            class="text-primary hover:underline"
            target="_blank"
            rel="noopener"
            >Creative Commons Attribution-ShareAlike 4.0 International
            License</a
          >. Website design adapted from
          <a
            href="https://nerfies.github.io/"
            class="text-primary hover:underline"
            target="_blank"
            rel="noopener"
            >Nerfies</a
          >.
        </p>
      </div>
    </footer>

    <!-- Image Modal -->
    <div
      id="imageModal"
      class="fixed inset-0 z-50 hidden items-center justify-center bg-black/90 p-4"
      onclick="closeImageModal()"
    >
      <button
        class="absolute top-4 right-4 text-white hover:text-slate-300 transition"
        onclick="closeImageModal()"
        aria-label="Close modal"
      >
        <svg
          class="h-8 w-8"
          fill="none"
          stroke="currentColor"
          viewBox="0 0 24 24"
          xmlns="http://www.w3.org/2000/svg"
        >
          <path
            stroke-linecap="round"
            stroke-linejoin="round"
            stroke-width="2"
            d="M6 18L18 6M6 6l12 12"
          ></path>
        </svg>
      </button>
      <img
        id="modalImage"
        src="assets/images/teaser_figure.png"
        alt="ParallelBench: Overview of limitations, analysis, and benchmark"
        class="max-h-full max-w-full object-contain p-8 bg-white rounded-2xl"
        onclick="event.stopPropagation()"
      />
    </div>

    <script>
      const toggleButton = document.getElementById('menu-toggle');
      const mobileNav = document.getElementById('mobile-nav');

      if (toggleButton) {
        toggleButton.addEventListener('click', () => {
          mobileNav.classList.toggle('hidden');
        });
      }

      // Image modal functions
      function openImageModal() {
        const modal = document.getElementById('imageModal');
        modal.classList.remove('hidden');
        modal.classList.add('flex');
        document.body.style.overflow = 'hidden';
      }

      function closeImageModal() {
        const modal = document.getElementById('imageModal');
        modal.classList.remove('flex');
        modal.classList.add('hidden');
        document.body.style.overflow = '';
      }

      // Close modal on Escape key
      document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape') {
          closeImageModal();
        }
      });
    </script>
  </body>
</html>
