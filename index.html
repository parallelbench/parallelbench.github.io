<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      ParallelBench: Understanding the Trade-offs of Parallel Decoding in
      Diffusion LLMs
    </title>
    <meta
      name="description"
      content="ParallelBench analyzes diffusion LLMs under parallel decoding, revealing the speed-quality trade-offs and benchmark tracks that surface token dependency failures."
    />
    <link rel="icon" href="favicon.ico" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap"
      rel="stylesheet"
    />
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            fontFamily: {
              sans: ['Inter', 'ui-sans-serif', 'system-ui'],
            },
            colors: {
              primary: '#1f6feb',
              slateInk: '#0b192f',
            },
            boxShadow: {
              card: '0 24px 48px -32px rgba(15, 23, 42, 0.35)',
            },
          },
        },
      };
    </script>
    <style>
      body {
        font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont,
          'Segoe UI', sans-serif;
      }
    </style>
  </head>
  <body class="bg-white text-slate-900 antialiased">
    <header
      class="sticky top-0 z-40 border-b border-slate-200 bg-white/90 backdrop-blur"
    >
      <div
        class="mx-auto flex max-w-6xl items-center justify-between px-6 py-3 lg:px-12"
      >
        <a
          href="#top"
          class="flex items-center gap-3 text-base font-semibold text-slate-800"
        >
          <img
            src="assets/images/logo.png"
            alt="ParallelBench logo"
            class="h-10 w-10 border border-slate-200 bg-white object-cover rounded-full"
          />
          <span>ParallelBench</span>
        </a>
        <button
          type="button"
          id="menu-toggle"
          class="rounded-md border border-slate-200 px-3 py-2 text-sm font-medium text-slate-600 transition hover:border-primary/40 hover:text-primary lg:hidden"
        >
          Menu
        </button>
        <nav
          id="main-nav"
          class="hidden items-center gap-6 text-sm font-medium text-slate-600 lg:flex"
        >
          <a href="#overview" class="transition hover:text-primary">Overview</a>
          <a href="#benchmark" class="transition hover:text-primary"
            >Benchmark</a
          >
          <a href="#tracks" class="transition hover:text-primary">Tracks</a>
          <a href="#evaluation" class="transition hover:text-primary"
            >Evaluation</a
          >
          <a href="#findings" class="transition hover:text-primary">Findings</a>
          <a href="#citation" class="transition hover:text-primary">Citation</a>
        </nav>
      </div>
      <div
        id="mobile-nav"
        class="hidden border-t border-slate-200 bg-white px-6 py-4 text-sm font-medium text-slate-600 lg:hidden"
      >
        <div class="flex flex-col gap-3">
          <a href="#overview" class="transition hover:text-primary">Overview</a>
          <a href="#benchmark" class="transition hover:text-primary"
            >Benchmark</a
          >
          <a href="#tracks" class="transition hover:text-primary">Tracks</a>
          <a href="#evaluation" class="transition hover:text-primary"
            >Evaluation</a
          >
          <a href="#findings" class="transition hover:text-primary">Findings</a>
          <a href="#citation" class="transition hover:text-primary">Citation</a>
        </div>
      </div>
    </header>

    <main id="top">
      <section
        class="relative overflow-hidden bg-gradient-to-br from-slate-50 via-white to-white"
      >
        <div
          class="absolute -top-10 right-12 h-64 w-64 rounded-full bg-primary/10 blur-3xl"
        ></div>
        <div
          class="absolute bottom-24 left-12 h-80 w-80 rounded-full bg-slate-200/50 blur-3xl"
        ></div>
        <div
          class="relative mx-auto max-w-5xl px-6 pb-24 pt-16 text-center lg:px-12 lg:pb-28 lg:pt-20"
        >
          <div class="mx-auto flex w-full max-w-md flex-col items-center gap-4">
            <img
              src="assets/images/logo.png"
              alt="ParallelBench logo"
              class="h-28 object-cover"
            />
          </div>
          <h1
            class="mt-8 text-4xl font-bold leading-tight text-slateInk sm:text-5xl"
          >
            ParallelBench: Understanding the Trade-offs of Parallel Decoding in
            Diffusion LLMs
          </h1>
          <p class="mx-auto mt-6 max-w-3xl text-lg text-slate-600">
            While most autoregressive LLMs are constrained to one-by-one
            decoding, diffusion LLMs (dLLMs) have attracted growing interest for
            their potential to dramatically accelerate inference through
            parallel decoding. We introduce ParallelBench, the first benchmark
            specifically designed for dLLMs, featuring realistic tasks that are
            trivial for humans and autoregressive LLMs yet exceptionally
            challenging for dLLMs under parallel decoding.
          </p>
          <div class="mt-8 space-y-4 text-sm text-slate-600">
            <p class="mx-auto text-center max-w-2xl">
              Wonjun Kang*<sup>1</sup>, Kevin Galim*<sup>1</sup>, Seunghyuk
              Oh*<sup>1</sup>, Minjae Lee<sup>1</sup>, Yuchen Zeng<sup>2</sup
              ><sup>3</sup>, Shuibai Zhang<sup>2</sup>, Coleman Richard Charles
              Hooper<sup>4</sup>, Yuezhou Hu<sup>4</sup>, Hyung Il
              Koo<sup>1</sup>, Nam Ik Cho<sup>5</sup>, Kangwook Lee<sup>2</sup>
            </p>
            <div
              class="flex flex-wrap items-center justify-center gap-4 text-xs text-slate-500"
            >
              <span
                ><strong><sup>1</sup> FuriosaAI</strong></span
              >
              <span
                ><strong><sup>2</sup> UW-Madison</strong></span
              >
              <span
                ><strong><sup>3</sup> Microsoft Research</strong></span
              >
              <span
                ><strong><sup>4</sup> UC Berkeley</strong></span
              >
              <span
                ><strong><sup>5</sup> Seoul National University</strong></span
              >
            </div>
            <div class="text-xs text-slate-500">
              <p>*Equal Contribution</p>
            </div>
          </div>
          <div class="mt-10 flex flex-wrap items-center justify-center gap-4">
            <a
              href="https://github.com/furiosa-ai/ParallelBench"
              class="inline-flex items-center gap-2 rounded-full border border-slate-200 bg-white px-6 py-3 text-sm font-semibold text-slate-700 shadow-card transition hover:border-primary/40 hover:text-primary"
              target="_blank"
              rel="noopener noreferrer"
            >
              <span>GitHub Repository</span>
              <svg
                class="h-4 w-4"
                fill="none"
                stroke="currentColor"
                viewBox="0 0 24 24"
                xmlns="http://www.w3.org/2000/svg"
              >
                <path
                  stroke-linecap="round"
                  stroke-linejoin="round"
                  stroke-width="2"
                  d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"
                ></path>
              </svg>
            </a>
            <a
              href="#abstract"
              class="inline-flex items-center gap-2 rounded-full border border-primary/40 bg-primary/10 px-6 py-3 text-sm font-semibold text-primary transition hover:bg-primary/20"
            >
              <span>📄</span>
              <span>Read the full Abstract</span>
            </a>
          </div>
        </div>
      </section>

      <section id="overview" class="bg-white pt-10 pb-20">
        <div class="mx-auto max-w-5xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Why ParallelBench?
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            Despite the promise of parallel decoding, the conditional
            independence assumption in dLLMs causes quality degradation when
            token dependencies are strong. However, existing works largely
            overlook these challenges, and standard benchmarks (e.g., math and
            coding) fail to capture this degradation. ParallelBench bridges
            theory and practice with both information-theoretic analysis and
            realistic tasks designed to expose these failures.
          </p>
          <div class="mt-10 grid gap-6 sm:grid-cols-2 lg:grid-cols-3">
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Information-Theoretic Analysis
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Proves that parallel decoding has fundamental error bounds when
                tokens depend on each other, showing even perfect models
                struggle as we increase parallelism on tasks requiring strong
                token coordination.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Quantitative Case Studies
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Analytically tractable synthetic list operations (Copy, Replace,
                Shuffle) with closed-form accuracy formulas demonstrate
                fundamental limitations: certain tasks show inevitable quality
                degradation under parallel decoding.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Realistic Benchmark Tasks
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                17 tasks across Waiting Line, Text Writing, and Puzzles—all
                trivial for humans and autoregressive LLMs—reveal severe quality
                degradation in dLLMs under parallel decoding in real-world
                scenarios.
              </p>
            </div>
          </div>
        </div>
      </section>

      <section
        id="benchmark"
        class="border-t border-slate-200 bg-slate-50 py-20"
      >
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Benchmark Highlights
          </h2>
          <div class="mt-10 grid gap-8 lg:grid-cols-[1.4fr,1fr]">
            <div class="space-y-6 text-base text-slate-600">
              <p>
                ParallelBench couples synthetic and realistic workloads to
                isolate where parallel decoding collapses. Each task family
                includes rubric-aligned solutions, baseline outputs, and
                instrumentation for measuring latency, perplexity, and
                dependency violations.
              </p>
              <ul class="space-y-3 text-sm">
                <li>
                  • 17 tasks across 3 categories: Waiting Line (10 tasks), Text
                  Writing (5 tasks), and Puzzles (2 tasks).
                </li>
                <li>
                  • Tasks with adjustable difficulty levels to test
                  parallelizability and adaptive decoding strategies.
                </li>
                <li>
                  • Reference implementations for diffusion LLMs and
                  autoregressive baselines.
                </li>
                <li>
                  • Evaluation harness capturing both quality and realized
                  parallel speedup.
                </li>
              </ul>
            </div>
            <div
              class="rounded-3xl border border-primary/30 bg-primary/5 p-8 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-primary">What You Get</h3>
              <ul class="mt-4 space-y-3 text-sm text-slate-600">
                <li>
                  <strong>Datasets:</strong> JSON/CSV payloads with gold outputs
                  and scoring scripts.
                </li>
                <li>
                  <strong>Tracing Tools:</strong> Hooks to log per-step token
                  dependencies and failure reasons.
                </li>
                <li>
                  <strong>Reports:</strong> Ready-made notebooks summarizing
                  baseline speed-quality curves.
                </li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      <section id="tracks" class="bg-white py-20">
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Benchmark Categories
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            ParallelBench consists of 17 tasks across three categories. Together
            they reveal how parallel decoding struggles when tokens need to
            coordinate with each other, ranging from tasks where each token is
            independent to those requiring strong interdependencies.
          </p>
          <div class="mt-12 grid gap-8 lg:grid-cols-3">
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-slate-50 p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Waiting Line (10 tasks)
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Realistic customer service queue management tasks extending
                synthetic list operations (Copy, Sort, Reverse, Shuffle,
                Insert/Remove/Replace Index/Random) to expose where parallel
                decoding fails to maintain token dependencies.
              </p>
              <ul class="mt-6 space-y-2 text-sm text-slate-500">
                <li>• Adjustable queue length (n = 3-20)</li>
                <li>• Independent tokens vs. interdependent tokens</li>
                <li>• Accuracy-based evaluation</li>
              </ul>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-slate-50 p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Text Writing (5 tasks)
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Summarization, paraphrasing, and Words-to-Sentence generation
                tasks at varying difficulty levels that expose quality
                degradation through grammar scores and token-level dependencies.
              </p>
              <ul class="mt-6 space-y-2 text-sm text-slate-500">
                <li>• Grammar score evaluation</li>
                <li>• Three difficulty levels for W2S</li>
                <li>• Standard datasets (SAMSum, ChatGPT-Paraphrases)</li>
              </ul>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-slate-50 p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Puzzles (2 tasks)
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Sudoku (4x4) and Latin Square (3x3) tasks that compare
                structurally similar puzzles with different solution spaces to
                demonstrate how token dependencies affect parallel decoding
                performance.
              </p>
              <ul class="mt-6 space-y-2 text-sm text-slate-500">
                <li>• Sudoku: unique solution (fully constrained)</li>
                <li>
                  • Latin Square: multiple solutions (loosely constrained)
                </li>
                <li>• Planning capability assessment</li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      <section id="examples" class="bg-white pt-5 pb-20">
        <div class="mx-auto max-w-5xl px-6 lg:px-0">
          <div
            class="rounded-3xl border border-slate-200 bg-slate-50 p-6 text-sm text-slate-600 shadow-sm"
          >
            <h3 class="text-lg font-semibold text-slateInk">
              Sample Prompt: Waiting Line (Shuffle)
            </h3>
            <pre
              class="mt-4 overflow-x-auto rounded-2xl bg-slate-900/95 p-4 text-sm text-slate-100"
            >
You are managing a waiting line at a customer service desk. The waiting line should be
randomly shuffled to ensure fair service distribution: ["Thomas Holmes", "Keith Ramos",
"Victoria Collins", "Roger Hughes", "Austin Dunn"]. Please randomly shuffle the list.
Ensure the sequence is different from the original. Think step by step and give your
final answer.</pre
            >
            <h3 class="mt-6 text-lg font-semibold text-slateInk">
              Sample Prompt: Text Writing (Words-to-Sentence)
            </h3>
            <pre
              class="mt-4 overflow-x-auto rounded-2xl bg-slate-900/95 p-4 text-sm text-slate-100"
            >
Construct a single, coherent sentence using the words algorithm, river, symphony, and moss.</pre
            >
            <h3 class="mt-6 text-lg font-semibold text-slateInk">
              Sample Prompt: Puzzles (Latin Square)
            </h3>
            <pre
              class="mt-4 overflow-x-auto rounded-2xl bg-slate-900/95 p-4 text-sm text-slate-100"
            >
Generate a Latin square of size 3 with the symbols [A, W, M]. Only output the final result
as CSV.</pre
            >
          </div>
        </div>
      </section>

      <section
        id="evaluation"
        class="border-t border-slate-200 bg-slate-50 py-20"
      >
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Evaluation Framework
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            We use simple, task-specific evaluation metrics tailored to each
            category. For Waiting Line and Puzzles, we measure exact match
            accuracy. For Text Writing, we use grammar scoring combined with
            task-appropriate metrics.
          </p>
          <div class="mt-12 grid gap-8 lg:grid-cols-3">
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Waiting Line & Puzzles
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                <strong>Accuracy:</strong> Binary score indicating whether the
                generated output exactly matches one of the valid solutions. For
                structured tasks like queue management and logic puzzles, exact
                correctness is essential.
              </p>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">Text Writing</h3>
              <p class="mt-3 text-sm text-slate-600">
                <strong>Grammar Score:</strong> Evaluated using
                LanguageTool—outputs receive 1 if grammatically correct, 0
                otherwise. Additional task-specific metrics include ROUGE-L for
                summarization, BERTScore and (1 - BLEU) for paraphrasing, and
                word inclusion accuracy for Words-to-Sentence tasks.
              </p>
            </div>
            <div
              class="flex h-full flex-col rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3 class="text-lg font-semibold text-slateInk">
                Decoding Setup
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                All models use greedy decoding, except for infilling tasks which
                use temperature sampling (τ = 1.0). Maximum generation length is
                set to 32 tokens for Waiting Line and 64 tokens for both Puzzle
                and Text Writing tasks.
              </p>
            </div>
          </div>
        </div>
      </section>

      <section id="leaderboard" class="bg-white py-20">
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Baseline Snapshot
          </h2>
          <p
            class="mx-auto mt-6 max-w-3xl text-center text-base text-slate-600"
          >
            Autoregressive LLMs maintain high quality, while diffusion LLMs with
            parallel decoding (k=2) struggle with tasks requiring strong token
            dependencies. Results show average scores across Waiting Line tasks
            with n=3-6.
          </p>
          <div
            class="mt-10 overflow-x-auto rounded-3xl border border-slate-200 bg-white shadow-card"
          >
            <table class="min-w-full divide-y divide-slate-200 text-sm">
              <thead
                class="bg-slate-50 text-xs font-semibold uppercase tracking-wide text-slate-600"
              >
                <tr>
                  <th class="px-4 py-3 text-left">Model</th>
                  <th class="px-4 py-3 text-left">Type</th>
                  <th class="px-4 py-3 text-center">Copy</th>
                  <th class="px-4 py-3 text-center">Reverse</th>
                  <th class="px-4 py-3 text-center">Shuffle</th>
                  <th class="px-4 py-3 text-center">Replace Idx</th>
                  <th class="px-4 py-3 text-center">Replace Rand</th>
                </tr>
              </thead>
              <tbody class="divide-y divide-slate-100 text-slate-700">
                <tr class="bg-blue-50/40">
                  <td class="px-4 py-3 font-semibold">Llama 3.1 8B</td>
                  <td class="px-4 py-3">Autoregressive</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">96</td>
                  <td class="px-4 py-3 text-center">23</td>
                  <td class="px-4 py-3 text-center">88</td>
                </tr>
                <tr class="bg-blue-50/40">
                  <td class="px-4 py-3 font-semibold">Qwen3 4B</td>
                  <td class="px-4 py-3">Autoregressive</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">75</td>
                  <td class="px-4 py-3 text-center">97</td>
                  <td class="px-4 py-3 text-center">67</td>
                  <td class="px-4 py-3 text-center">92</td>
                </tr>
                <tr class="bg-purple-50/40">
                  <td class="px-4 py-3 font-semibold">Claude Haiku 3.5</td>
                  <td class="px-4 py-3">Closed (AR)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">32</td>
                  <td class="px-4 py-3 text-center">100</td>
                </tr>
                <tr class="bg-amber-50/60">
                  <td class="px-4 py-3 font-semibold">LLaDA 1.5</td>
                  <td class="px-4 py-3">Diffusion (k=2)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">99</td>
                  <td class="px-4 py-3 text-center">18</td>
                  <td class="px-4 py-3 text-center">15</td>
                  <td class="px-4 py-3 text-center">70</td>
                </tr>
                <tr class="bg-amber-50/60">
                  <td class="px-4 py-3 font-semibold">Dream 7B</td>
                  <td class="px-4 py-3">Diffusion (k=2)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">91</td>
                  <td class="px-4 py-3 text-center">87</td>
                  <td class="px-4 py-3 text-center">27</td>
                  <td class="px-4 py-3 text-center">99</td>
                </tr>
                <tr class="bg-amber-50/60">
                  <td class="px-4 py-3 font-semibold">Mercury</td>
                  <td class="px-4 py-3">Closed (Diffusion)</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">100</td>
                  <td class="px-4 py-3 text-center">92</td>
                  <td class="px-4 py-3 text-center">28</td>
                  <td class="px-4 py-3 text-center">98</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </section>

      <section
        id="findings"
        class="border-t border-slate-200 bg-slate-50 py-20"
      >
        <div class="mx-auto max-w-6xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Key Findings
          </h2>
          <div class="mt-12 grid gap-8 lg:grid-cols-2">
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                ⚠️ Quality Collapse Under Independence
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                dLLMs incur catastrophic accuracy drops (20-40 points) when
                token dependencies extend beyond their parallel decoding
                horizon, even on tasks solvable analytically.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                ⚖️ Speed vs. Quality Trade-off
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Increasing parallelism rarely yields net wins: most strategies
                plateau at &lt;1.5× throughput while degrading accuracy by
                &gt;15 points.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                🧠 Adaptivity Is Lacking
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                Current decoding heuristics fail to dial back parallelism for
                harder tasks, suggesting the need for dependency-aware
                controllers.
              </p>
            </div>
            <div
              class="rounded-3xl border border-slate-200 bg-white p-6 shadow-sm"
            >
              <h3
                class="flex items-center gap-2 text-lg font-semibold text-slateInk"
              >
                🛠️ Benchmark as a Guide
              </h3>
              <p class="mt-3 text-sm text-slate-600">
                ParallelBench pinpoints concrete failure modes, enabling the
                community to prototype hybrid decoding and improved diffusion
                objectives.
              </p>
            </div>
          </div>
        </div>
      </section>

      <section id="abstract" class="bg-white py-20">
        <div class="mx-auto max-w-4xl px-6 lg:px-0">
          <h2 class="text-center text-3xl font-semibold text-slateInk">
            Abstract
          </h2>
          <div
            class="mt-8 space-y-6 text-justify text-base leading-7 text-slate-600"
          >
            <p>
              While most autoregressive LLMs are constrained to one-by-one
              decoding, diffusion LLMs (dLLMs) have attracted growing interest
              for their potential to dramatically accelerate inference through
              parallel decoding. Despite this promise, the conditional
              independence assumption in dLLMs causes parallel decoding to
              ignore token dependencies, inevitably degrading generation quality
              when these dependencies are strong. However, existing works
              largely overlook these inherent challenges, and evaluations on
              standard benchmarks (e.g., math and coding) are not sufficient to
              capture the quality degradation caused by parallel decoding. To
              address this gap, we first provide an information-theoretic
              analysis of parallel decoding. We then conduct case studies on
              analytically tractable synthetic list operations from both data
              distribution and decoding strategy perspectives, offering
              quantitative insights that highlight the fundamental limitations
              of parallel decoding. Building on these insights, we propose
              ParallelBench, the first benchmark specifically designed for
              dLLMs, featuring realistic tasks that are trivial for humans and
              autoregressive LLMs yet exceptionally challenging for dLLMs under
              parallel decoding. Using ParallelBench, we systematically analyze
              both dLLMs and autoregressive LLMs, revealing that: (i) dLLMs
              under parallel decoding can suffer dramatic quality degradation in
              real-world scenarios, and (ii) current parallel decoding
              strategies struggle to adapt their degree of parallelism based on
              task difficulty, thus failing to achieve meaningful speedup
              without compromising quality. Our findings underscore the pressing
              need for innovative decoding methods that can overcome the current
              speed-quality trade-off. We are releasing our benchmark to help
              accelerate the development of truly efficient dLLMs.
            </p>
          </div>
          <div class="mx-auto mt-12 max-w-6xl px-6 lg:px-0">
            <div
              class="overflow-hidden rounded-3xl border border-slate-200 bg-white shadow-card p-6 lg:p-8"
            >
              <img
                src="assets/images/teaser_figure.png"
                alt="ParallelBench: Overview of limitations, analysis, and benchmark"
                class="w-full"
              />
            </div>
            <p class="mt-4 text-center text-sm text-slate-500">
              Figure 1: ParallelBench addresses three key aspects—(left)
              limitations of parallel decoding, (middle) quantitative analysis
              on list operations, and (right) a comprehensive benchmark to
              assess speed-quality trade-offs in diffusion LLMs.
            </p>
          </div>
        </div>
      </section>
    </main>

    <footer id="citation" class="border-t border-slate-200 bg-slate-50 py-12">
      <div
        class="mx-auto flex max-w-5xl flex-col items-center gap-4 px-6 text-center text-sm text-slate-500"
      >
        <h3 class="text-base font-semibold text-slateInk">Citation</h3>
        <pre
          class="w-full overflow-x-auto rounded-3xl border border-slate-200 bg-slate-900/95 p-6 text-left text-sm text-slate-100"
        >
@misc{parallelbench2025,
  title={ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs},
  author={Wonjun Kang and Kevin Galim and Seunghyuk Oh and Minjae Lee and Yuchen Zeng and
          Shuibai Zhang and Coleman Richard Charles Hooper and Yuezhou Hu and
          Hyung Il Koo and Nam Ik Cho and Kangwook Lee},
  year={2025},
  note={Under review as a conference paper at ICLR 2026},
  howpublished={\url{https://github.com/furiosa-ai/ParallelBench}}
}</pre
        >
        <p>
          This webpage is licensed under a
          <a
            href="http://creativecommons.org/licenses/by-sa/4.0/"
            class="text-primary hover:underline"
            target="_blank"
            rel="noopener"
            >Creative Commons Attribution-ShareAlike 4.0 International
            License</a
          >. Website design adapted from
          <a
            href="https://nerfies.github.io/"
            class="text-primary hover:underline"
            target="_blank"
            rel="noopener"
            >Nerfies</a
          >.
        </p>
      </div>
    </footer>

    <script>
      const toggleButton = document.getElementById('menu-toggle');
      const mobileNav = document.getElementById('mobile-nav');

      if (toggleButton) {
        toggleButton.addEventListener('click', () => {
          mobileNav.classList.toggle('hidden');
        });
      }
    </script>
  </body>
</html>
