<section id="comparison" class="bg-white py-16 sm:py-20 lg:py-28">
  <div class="mx-auto max-w-5xl px-6 lg:px-12">
    <div class="text-center mb-16">
      <h2 class="text-3xl font-bold text-slate-900 sm:text-4xl">
        Cross-Model Comparison
      </h2>
      <p
        class="mx-auto mt-5 max-w-4xl text-base text-slate-600 leading-relaxed"
      >
        The speed-quality trade-off is not unique to LLaDA.<br />
        Closed-source dLLM <b>Mercury</b> and autoregressive LLMs show
        contrasting behaviors.
      </p>
    </div>

    <!-- dLLM vs AR LLM Comparison -->
    <div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-6 mb-8">
      <!-- Mercury -->
      <figure class="my-4">
        <div
          class="rounded-xl border border-slate-200 bg-white p-3 sm:p-4 transition"
        >
          <img
            src="assets/figures/comparison/mercury.png"
            alt="Mercury (dLLM) results"
            class="w-full h-auto rounded-lg"
            loading="lazy"
          />
        </div>
        <figcaption class="mt-2 text-center text-sm text-slate-500 font-medium">
          Mercury (dLLM)
        </figcaption>
      </figure>

      <!-- Claude Haiku -->
      <figure class="my-4">
        <div
          class="rounded-xl border border-slate-200 bg-white p-3 sm:p-4 transition"
        >
          <img
            src="assets/figures/comparison/claude_haiku.png"
            alt="Claude 3.5 Haiku results"
            class="w-full h-auto rounded-lg"
            loading="lazy"
          />
        </div>
        <figcaption class="mt-2 text-center text-sm text-slate-500 font-medium">
          Claude 3.5 Haiku (AR)
        </figcaption>
      </figure>

      <!-- Qwen 3B -->
      <figure class="my-4">
        <div
          class="rounded-xl border border-slate-200 bg-white p-3 sm:p-4 transition"
        >
          <img
            src="assets/figures/comparison/qwen_3.png"
            alt="Qwen2.5 3B results"
            class="w-full h-auto rounded-lg"
            loading="lazy"
          />
        </div>
        <figcaption class="mt-2 text-center text-sm text-slate-500 font-medium">
          Qwen2.5 3B (AR)
        </figcaption>
      </figure>
    </div>

    <!-- Key Insight Box -->
    <div
      class="rounded-lg bg-blue-50 border border-blue-200 p-5 max-w-5xl mx-auto"
    >
      <div class="flex items-start gap-3">
        <div class="flex-shrink-0 rounded-lg bg-blue-100 p-2 text-blue-600">
          <svg
            class="h-5 w-5"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"
            />
          </svg>
        </div>
        <div>
          <h4 class="text-sm font-semibold text-slate-900 mb-1">Key Insight</h4>
          <p class="text-sm text-slate-700 leading-relaxed">
            Mercury and autoregressive LLMs show opposite accuracy trends on
            Reverse and Shuffle. Mercury maintains near-perfect accuracy on
            Reverse but fails with Shuffle, with accuracy dropping sharply as n
            increases. This indicates that the closed-source Mercury struggles
            to adaptively adjust its parallelism to maintain quality on tasks
            with high token dependencies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
